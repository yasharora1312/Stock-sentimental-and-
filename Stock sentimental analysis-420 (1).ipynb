{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "258d153a-4432-450b-8729-999b20eae001",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install textblob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6798118c-4bf3-4330-8441-f831dd098948",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "910ae391-4eca-408d-89fa-bf5e3de5cee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install webdriver_manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9a82a3c-485e-4ac9-9fb7-d14b11830e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install dateparser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34326a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import unicodedata\n",
    "import os\n",
    "import yfinance as yf\n",
    "import math\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import nltk\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from matplotlib.dates import DateFormatter\n",
    "import statistics\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from textblob import TextBlob, Word\n",
    "from datetime import datetime, timedelta\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9988c59b",
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('vader_lexicon')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ae62135-8274-4d0a-8847-ac46d961e71f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "current_directory = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba4411d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tickers = ['V', 'MA', 'JNJ', 'NVDA', 'KO', 'AAPL']\n",
    "stock_tweet_path=current_directory+\"/stock_tweets.csv\"\n",
    "stock_data_path=current_directory+\"/stock_data.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d06abf98",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "# Setup Selenium WebDriver\n",
    "service = Service(ChromeDriverManager().install())\n",
    "chrome_options = webdriver.ChromeOptions()\n",
    "chrome_options.add_argument(\"--headless\")  # Enable headless mode\n",
    "chrome_options.add_argument(\"--no-sandbox\")\n",
    "chrome_options.add_argument(\"--disable-dev-shm-usage\")\n",
    "driver = webdriver.Chrome(service=service, options=chrome_options)\n",
    "\n",
    "tickers = ['V', 'MA', 'JNJ', 'NVDA', 'KO', 'AAPL']\n",
    "\n",
    "def last_12_months(time_text):\n",
    "    if 'months' in time_text:\n",
    "        months = int(time_text.split()[0])\n",
    "        return months <= 12\n",
    "    return True\n",
    "\n",
    "# Initialize an empty DataFrame to collect all news\n",
    "news = pd.DataFrame()\n",
    "\n",
    "for ticker in tickers:\n",
    "    url = f'https://finance.yahoo.com/quote/{ticker}/news/'\n",
    "    driver.get(url)\n",
    "    time.sleep(4)\n",
    "    print(f'Collecting news related to {ticker}')\n",
    "    previous_height = driver.execute_script('return document.body.scrollHeight')\n",
    "    count = 0\n",
    "    n = []\n",
    "    \n",
    "    while True:\n",
    "        content_divs = driver.find_elements(By.CSS_SELECTOR, 'div.content.svelte-w27v8j')\n",
    "        \n",
    "        latest_time_text = ''\n",
    "        for content_div in content_divs:\n",
    "            try:\n",
    "                a_tag = content_div.find_element(By.CSS_SELECTOR, 'a.subtle-link.fin-size-small.titles.noUnderline.svelte-wdkn18')\n",
    "                title = a_tag.get_attribute('title') if a_tag else None\n",
    "                \n",
    "                publishing_div = content_div.find_element(By.CSS_SELECTOR, 'div.publishing.font-condensed.svelte-1k3af9g')\n",
    "                time_text = publishing_div.text.split('â€¢')[-1].strip() if publishing_div else None\n",
    "                latest_time_text = time_text\n",
    "                if latest_time_text and last_12_months(latest_time_text):\n",
    "                    n.append({'Date': time_text, 'Headline': title, 'Stock Name': ticker})\n",
    "            except Exception as e:\n",
    "                print(f\"Error extracting data: {e}\")\n",
    "\n",
    "        driver.execute_script('window.scrollTo(0, document.body.scrollHeight)')\n",
    "        time.sleep(4)\n",
    "        new_height = driver.execute_script('return document.body.scrollHeight')\n",
    "        \n",
    "        if new_height == previous_height:\n",
    "            count += 1\n",
    "            if count > 4:\n",
    "                break\n",
    "        else:\n",
    "            previous_height = new_height\n",
    "            count = 0\n",
    "        \n",
    "        if latest_time_text and not last_12_months(latest_time_text):\n",
    "            break\n",
    "    \n",
    "    df_news = pd.DataFrame(n)\n",
    "    \n",
    "    if not df_news.empty:\n",
    "        print(f'Starting news related to {ticker} is {df_news[\"Date\"].iloc[0]}')\n",
    "        print(f'Ending news related to {ticker} is {df_news[\"Date\"].iloc[-1]}')\n",
    "        print('Dataset size is ', df_news.shape[0])\n",
    "        news = pd.concat([news, df_news], ignore_index=True)\n",
    "\n",
    "# Close the WebDriver\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0b6bf08-5879-4545-bc52-585ebaa1cf5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import time\n",
    "\n",
    "def fetch_data(year, month, api_key):\n",
    "    url = f\"https://api.nytimes.com/svc/archive/v1/{year}/{month}.json?api-key={api_key}\"\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        articles = data['response']['docs']\n",
    "        return articles\n",
    "    else:\n",
    "        print(f\"Failed to fetch data for {year}-{month}: {response.status_code}\")\n",
    "        return []\n",
    "\n",
    "# Initialize lists for headlines and dates\n",
    "all_news = []\n",
    "all_dates = []\n",
    "\n",
    "# API key\n",
    "api_key = 'Z7LiuLGnozS868StkM3QcbQhsJA8acDt'\n",
    "\n",
    "# Fetch data for each year from 2010 to 2024\n",
    "for year in range(2016, 2024):\n",
    "    for month in range(1, 13):\n",
    "        print(f\"Fetching data for {year}-{month}\")\n",
    "        try:\n",
    "            articles = fetch_data(year, month, api_key)\n",
    "            if articles:\n",
    "                all_news.extend([article['headline']['main'] for article in articles])\n",
    "                all_dates.extend([article['pub_date'] for article in articles])\n",
    "            # Sleep to respect API rate limits\n",
    "            time.sleep(6)  # Adjust sleep time as needed based on API rate limits\n",
    "        except Exception as e:\n",
    "            print(f\"Error fetching data for {year}-{month}: {e}\")\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame({'datetime': all_dates, 'news': all_news})\n",
    "\n",
    "# Convert datetime column to datetime format\n",
    "df['datetime'] = pd.to_datetime(df['datetime'])\n",
    "\n",
    "# Extract date\n",
    "df['date'] = df['datetime'].dt.date\n",
    "\n",
    "# Filter articles containing information about nvidia company stock\n",
    "keywords = ['Nvidia', 'NVDA', 'Nvidia Corporation', 'nvidia stock', 'nvidia shares']\n",
    "df['contains_nvidia_stock_info'] = df['news'].apply(lambda x: any(keyword in x for keyword in keywords))\n",
    "\n",
    "# Create a filtered DataFrame\n",
    "nvidia_stock_df = df[df['contains_nvidia_stock_info']]\n",
    "\n",
    "# Group by date and concatenate news articles\n",
    "grouped_nvidia_df = nvidia_stock_df.groupby('date')['news'].agg(' '.join).reset_index()\n",
    "\n",
    "# Rename columns and convert Date to datetime format\n",
    "grouped_nvidia_df.columns = ['Date', 'news_articles']\n",
    "grouped_nvidia_df['Date'] = pd.to_datetime(grouped_nvidia_df['Date'])\n",
    "\n",
    "# Print the resulting DataFrame\n",
    "print(grouped_nvidia_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0b1d87b-b088-40bf-8535-d5c1875e85f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_nvidia_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f99162f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "news.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d74a48a0-7f79-4cc2-8d48-9853924828af",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_nvidia_df.rename(columns={'news_articles': 'Headline'}, inplace=True)\n",
    "stock_name = 'NVDA'  # Replace with the actual stock name\n",
    "grouped_nvidia_df['Stock Name'] = stock_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adbdd675",
   "metadata": {},
   "outputs": [],
   "source": [
    "news.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb6ee1c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "news.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81ac14cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the collected news to a CSV file\n",
    "news.to_csv(stock_tweet_path, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c78f7f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_tweet_date_path=current_directory+'/stock_tweets_date.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e23dbe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to convert relative time text to actual date\n",
    "def convert_to_date(time_text):\n",
    "    now = datetime.now()\n",
    "    if time_text == 'yesterday':\n",
    "        return now - timedelta(days=1)\n",
    "    if time_text == 'last month':\n",
    "        return now - timedelta(days=30)\n",
    "    if 'minute' in time_text:\n",
    "        minutes = int(time_text.split()[0])\n",
    "        return now - timedelta(minutes=minutes)\n",
    "    elif 'hour' in time_text:\n",
    "        hours = int(time_text.split()[0])\n",
    "        return now - timedelta(hours=hours)\n",
    "    elif 'day' in time_text:\n",
    "        days = int(time_text.split()[0])\n",
    "        return now - timedelta(days=days)\n",
    "    elif 'week' in time_text:\n",
    "        weeks = int(time_text.split()[0])\n",
    "        return now - timedelta(weeks=weeks)\n",
    "    elif 'month' in time_text:\n",
    "        months = int(time_text.split()[0])\n",
    "        return now - timedelta(days=30*months)\n",
    "    elif 'today' in time_text.lower():\n",
    "        return now\n",
    "    else:\n",
    "        return None\n",
    "news['Date'] = news['Date'].apply(convert_to_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7c3e7be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the collected news to a CSV file\n",
    "news.to_csv(stock_tweet_date_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b070d7c-2432-47e7-b8bd-9b960064facd",
   "metadata": {},
   "outputs": [],
   "source": [
    "news=pd.read_csv('stock_tweets_date.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e98b29e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_price=pd.DataFrame()  # Example ticker symbol for nvidia\n",
    "start_date = \"2018-01-01\"  # Specify start date\n",
    "end_date = \"2024-06-19\"   \n",
    "dfs = [] \n",
    "for ticker in tickers:\n",
    "    data = yf.download(ticker, start=start_date, end=end_date).reset_index()  # Reset index to make 'Date' a column\n",
    "    data['Stock Name'] = ticker  # Add a column for the ticker symbol\n",
    "    dfs.append(data)\n",
    "\n",
    "# Combine all individual dataframes into a single dataframe\n",
    "stock_price = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "# Reorder columns as per the desired format\n",
    "stock_price = stock_price[['Date', 'Open', 'High', 'Low', 'Close', 'Adj Close', 'Volume', 'Stock Name']]\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "352d7073",
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_price.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03002f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_price['Stock Name'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ca9c750",
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_price.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f46d2d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_price.to_csv(stock_data_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11002920",
   "metadata": {},
   "outputs": [],
   "source": [
    "news=pd.read_csv(stock_tweet_date_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1f51408",
   "metadata": {},
   "outputs": [],
   "source": [
    "news.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a98845a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(news['Stock Name'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "430b8d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "news.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4e4c8f3-b0ed-4c0e-a172-e960a7f486a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "news = pd.concat([news, grouped_nvidia_df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16260ca9-8051-4b40-b899-71f750a5f949",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_nvidia_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "236c141b",
   "metadata": {},
   "outputs": [],
   "source": [
    "news['polarity_score']=''\n",
    "news.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3ad3ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_analyze = SentimentIntensityAnalyzer()\n",
    "\n",
    "# Analyze each tweet and store the compound score\n",
    "for ind, row in news.iterrows():\n",
    "    sentence_i = unicodedata.normalize(\"NFKD\", row[\"Headline\"])\n",
    "    sent_sent = sent_analyze.polarity_scores(sentence_i)\n",
    "    news.at[ind, \"polarity_score\"] = sent_sent[\"compound\"]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03b2c169",
   "metadata": {},
   "outputs": [],
   "source": [
    "news.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cf98f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "news[\"sentiment_label\"] = news[\"Headline\"].apply(lambda x: \"pos\" if sent_analyze.polarity_scores(x)[\"compound\"] > 0 else (\"neu\" if sent_analyze.polarity_scores(x)[\"compound\"] ==0 else \"neg\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd60aa09",
   "metadata": {},
   "outputs": [],
   "source": [
    "news.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc12b2b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "news[\"sentiment_label\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea50900a",
   "metadata": {},
   "outputs": [],
   "source": [
    "news[\"sentiment_label\"] = LabelEncoder().fit_transform(news[\"sentiment_label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "670077b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "news[\"Date\"] = pd.to_datetime(news['Date'])\n",
    "news[\"Date\"] = news[\"Date\"].dt.date\n",
    "news.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d18fc14c-f89c-436c-9d64-3300100aeae7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68063703",
   "metadata": {},
   "outputs": [],
   "source": [
    "news[\"sentiment_label\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aad369b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "news.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2b419a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary to map (Date, Stock Name) to Pct Change\n",
    "pct_change_dict = stock_price.set_index(['Date', 'Stock Name'])['Pct Change'].to_dict()\n",
    "\n",
    "# Assign Pct Change values to headlines_df\n",
    "news['pct_change'] = news.apply(lambda row: pct_change_dict.get((row['Date'], row['Stock Name']), None), axis=1)\n",
    "\n",
    "# Calculate mean Pct Change for each Stock Name\n",
    "mean_pct_change = stock_price.groupby('Stock Name')['Pct Change'].mean().to_dict()\n",
    "\n",
    "# Fill NaN values with the mean Pct Change of the respective company\n",
    "news['pct_change'] = news.apply(lambda row: mean_pct_change[row['Stock Name']] if pd.isna(row['pct_change']) else row['pct_change'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4773fd59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing function\n",
    "def preprocessing(df):\n",
    "    # Convert to lower case\n",
    "    df = df.str.lower()\n",
    "    # Remove punctuation\n",
    "    df = df.str.replace('[^\\w\\s]', '', regex=True)\n",
    "    # Remove numbers\n",
    "    df = df.str.replace('\\d', '', regex=True)\n",
    "    # Remove stopwords\n",
    "    sw = stopwords.words('english')\n",
    "    df = df.apply(lambda x: \" \".join(x for x in str(x).split() if x not in sw))\n",
    "    # Remove infrequent words\n",
    "    temp_df = pd.Series(' '.join(df).split()).value_counts()\n",
    "    drops = temp_df[temp_df <= 1]\n",
    "    df = df.apply(lambda x: \" \".join(x for x in x.split() if x not in drops))\n",
    "    return df\n",
    "\n",
    "# Tokenization function\n",
    "def tokenization(df):\n",
    "    df = df.apply(lambda x: TextBlob(x).words)\n",
    "    return df\n",
    "\n",
    "# Lemmatization function\n",
    "def lemmatized(df):\n",
    "    df = df.apply(lambda x: \" \".join([Word(word).lemmatize() for word in x.split()]))\n",
    "    return df\n",
    "\n",
    "# Term frequency function\n",
    "def term_fre(df):\n",
    "    tf = df.apply(lambda x: pd.value_counts(x.split(\" \"))).sum(axis=0).reset_index()\n",
    "    tf.columns = ['words', 'tf']\n",
    "    tf_sorted = tf.sort_values(by='tf', ascending=False)\n",
    "    return tf_sorted\n",
    "\n",
    "# TF-IDF function\n",
    "def tfidf(X, fit_vectorizer=None):\n",
    "    if fit_vectorizer is None:\n",
    "        fit_vectorizer = TfidfVectorizer()\n",
    "        X_tf_idf_word = fit_vectorizer.fit_transform(X)\n",
    "    else:\n",
    "        X_tf_idf_word = fit_vectorizer.transform(X)\n",
    "    return X_tf_idf_word, fit_vectorizer\n",
    "\n",
    "# Function to preprocess and vectorize\n",
    "def givefinalX(X, vectorizer=None):\n",
    "    # Apply preprocessing\n",
    "    X = preprocessing(X)\n",
    "\n",
    "    # Apply tokenization (if needed)\n",
    "    # X = tokenization(X)\n",
    "\n",
    "    # Apply lemmatization\n",
    "    X = lemmatized(X)\n",
    "\n",
    "    # Convert to TF-IDF\n",
    "    X_tf_idf_word, vectorizer = tfidf(X, vectorizer)\n",
    "    return X_tf_idf_word, vectorizer\n",
    "\n",
    "\n",
    "# Split the data\n",
    "X = news['Headline']\n",
    "y = news['sentiment_label']\n",
    "# Split into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a01f0b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to TF-IDF\n",
    "X_tf_idf_word_train, vectorizer = givefinalX(X_train)\n",
    "\n",
    "X_tf_idf_word_test, _ = givefinalX(X_test, vectorizer)\n",
    "\n",
    "# Train RandomForestClassifier\n",
    "rf_model = RandomForestClassifier()\n",
    "rf_model.fit(X_tf_idf_word_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43b386f9",
   "metadata": {},
   "outputs": [],
   "source": [
    " # Cross-validation score\n",
    "cv_score = cross_val_score(rf_model, X_tf_idf_word_train, y_train, cv=5, n_jobs=-1).mean()\n",
    "print(f\"Cross-validation score: {cv_score}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82885e52",
   "metadata": {},
   "outputs": [],
   "source": [
    " # Predictions on test set\n",
    "pred = rf_model.predict(X_tf_idf_word_test)\n",
    "print(f\"Test set predictions: {pred}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff68e5ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on the test set\n",
    "test_score = rf_model.score(X_tf_idf_word_test, y_test)\n",
    "print(f\"Test set score: {test_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61523e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = news[[\"Date\",\"polarity_score\",\"Stock Name\"]]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78392fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f9a795d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Stock Name\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cabc616a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by \"Date\" and \"Stock Name\" and calculate the mean of \"sentence_score\"\n",
    "df_grouped = df.groupby([\"Date\", \"Stock Name\"]).mean().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c95c6fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_grouped.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bda399c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_grouped.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1672ed70",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_grouped['Stock Name'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "534b53a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_grouped.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96ade01c",
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_price=pd.read_csv(stock_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94e29548",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(stock_price.shape)\n",
    "stock_price.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a63a05d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_price['Stock Name'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa51b52c",
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_price['Stock Name'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32b087ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_price[\"Date\"]=pd.to_datetime(stock_price[\"Date\"])\n",
    "stock_price[\"Date\"]=stock_price[\"Date\"].dt.date\n",
    "print(stock_price.shape)\n",
    "stock_price.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "634e3640",
   "metadata": {},
   "outputs": [],
   "source": [
    "stk_name='NVDA'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32e68f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "stock = stock_price[stock_price[\"Stock Name\"] == stk_name]\n",
    "stock[\"Date\"] = pd.to_datetime(stock[\"Date\"])\n",
    "stock[\"Date\"] = stock[\"Date\"].dt.date\n",
    "# Reset the index of appl_stock\n",
    "stock.reset_index(drop=True, inplace=True)\n",
    "stock.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a26b99b",
   "metadata": {},
   "outputs": [],
   "source": [
    "stock.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cbe25e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now filter the grouped DataFrame for rows where 'Stock Name' is 'NVDA'\n",
    "df = df_grouped[df_grouped['Stock Name'] == stk_name]\n",
    "# Reset the index of appl_df\n",
    "df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "016c8191",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73e9a6b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now perform the join operation\n",
    "df = stock.join(df.set_index([\"Date\", \"Stock Name\"]), on=[\"Date\", \"Stock Name\"], how=\"inner\")\n",
    "df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feaec38c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e9e01d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a91c3a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(figsize=(15,8))\n",
    "ax.plot(df[\"Date\"], df[\"Adj Close\"])\n",
    "ax.set(xlabel=\"Date\",ylabel=\"USD\",title=f\"{stk_name} Stock Price\")\n",
    "ax.xaxis.set_major_formatter(DateFormatter(\"%Y\"))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86635c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(figsize=(15,8))\n",
    "ax.plot(df[\"Date\"], df[\"polarity_score\"])\n",
    "ax.set(xlabel=\"Date\",ylabel=\"polarity Score\",title=f\"{stk_name}'s Public Sentiment\")\n",
    "ax.xaxis.set_major_formatter(DateFormatter(\"%Y\"))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e7ac398",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fin_df = appl_df[[\"Date\",\"Close\",\"sentence_score\"]]\n",
    "fin_df=df\n",
    "# fin_df = fin_df.reset_index(drop=True)\n",
    "print(fin_df.shape)\n",
    "fin_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d6bc6e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def SentimentAdjustedMA(df, ma_days):\n",
    "    def weight_multiplier(close,sent_score):\n",
    "        maxi = max(close)\n",
    "        mini = min(close)\n",
    "        len_close = len(close)\n",
    "        if len_close<2:\n",
    "            interval = math.sqrt(close[0])\n",
    "        else:\n",
    "            interval = statistics.variance(close)\n",
    "        max_var = interval\n",
    "        weighted=0\n",
    "        for i in range(len_close):\n",
    "            if sent_score[i] < 0:\n",
    "                weighted += close[i] + (2*sent_score[i]*max_var)\n",
    "            else:\n",
    "                weighted += close[i] + (sent_score[i]*max_var)\n",
    "        return weighted/len_close-1\n",
    "    samas = [df.loc[0,\"Adj Close\"]]\n",
    "    rows = df.shape[0]\n",
    "    for i in range(1,rows):\n",
    "        if i < ma_days:\n",
    "            mini_df = df.iloc[:i+1,:]\n",
    "        elif i + ma_days >= rows:\n",
    "            mini_df = df.iloc[i:,:]\n",
    "        else:\n",
    "            mini_df = df.iloc[i-ma_days+1:i+1,:]\n",
    "        sama_value = weight_multiplier(mini_df[\"Adj Close\"].tolist(),mini_df[\"polarity_score\"].tolist())\n",
    "        samas.append(sama_value)\n",
    "    return samas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58b58632",
   "metadata": {},
   "outputs": [],
   "source": [
    "sma5= SentimentAdjustedMA(fin_df, ma_days=5)\n",
    "fin_df[\"SMA(5)\"] = sma5\n",
    "sma20= SentimentAdjustedMA(fin_df, ma_days=10)\n",
    "fin_df[\"SMA(20)\"] = sma20\n",
    "fin_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac9d0528",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(figsize=(15,8))\n",
    "ax.plot(fin_df[\"Date\"], fin_df[\"SMA(5)\"], label=\"SMA(5)\", linestyle=\"--\", color=\"g\")\n",
    "ax.plot(fin_df[\"Date\"], fin_df[\"Adj Close\"], label=\"Original\", color=\"b\")\n",
    "ax.set(xlabel=\"Date\",ylabel=\"USD\",title=f\"{stk_name} Stock Price\")\n",
    "ax.xaxis.set_major_formatter(DateFormatter(\"%Y\"))\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d66d13b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort the dataframe by the 'Date' column\n",
    "fin_df = fin_df.sort_values(by='Date')\n",
    "\n",
    "# Reset the index to keep the dataframe tidy\n",
    "fin_df = fin_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a681b063",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Generate signals based on polarity score and additional filter (SMA)\n",
    "def generate_signals(df):\n",
    "    df['SMA'] = df['Close'].rolling(window=20).mean()  # 20-day simple moving average\n",
    "    df['Signal'] = 0\n",
    "    df['Signal'] = np.where((df['polarity_score'] > 0) & (df['Close'] > df['SMA']), 1, df['Signal'])\n",
    "    df['Signal'] = np.where((df['polarity_score'] < 0) & (df['Close'] < df['SMA']), -1, df['Signal'])\n",
    "    df['Order'] = df['Signal'].diff()\n",
    "    return df\n",
    "\n",
    "# Calculate returns and performance metrics with stop-loss, take-profit, and position sizing\n",
    "def calculate_performance(df, initial_cash=1000, stop_loss_pct=0.10, take_profit_pct=0.20, position_size_pct=0.20):\n",
    "    cash = initial_cash\n",
    "    position = 0\n",
    "    purchase_price = 0\n",
    "    portfolio_values = []\n",
    "    \n",
    "    for index, row in df.iterrows():\n",
    "        if row['Order'] == -1 and cash > 0:  # Buy signal\n",
    "            position = (cash * position_size_pct) / row['Close']\n",
    "            cash += position * row['Close']\n",
    "            purchase_price = row['Close']\n",
    "        elif row['Order'] == 1 and position > 0:  # Sell signal\n",
    "            cash -= position * row['Close']\n",
    "            position = 0\n",
    "        elif position > 0:\n",
    "            if row['Close'] < purchase_price * (1 - stop_loss_pct):  # Stop-loss condition\n",
    "                cash += position * row['Close']\n",
    "                position = 0\n",
    "                df.loc[index, 'Order'] = -1  # Mark this as a sell due to stop-loss\n",
    "            elif row['Close'] > purchase_price * (1 + take_profit_pct):  # Take-profit condition\n",
    "                cash += position * row['Close']\n",
    "                position = 0\n",
    "                df.loc[index, 'Order'] = -1  # Mark this as a sell due to take-profit\n",
    "\n",
    "        portfolio_value = cash + position * row['Close']\n",
    "        portfolio_values.append(portfolio_value)\n",
    "\n",
    "    df['Portfolio Value'] = portfolio_values\n",
    "    final_portfolio_value = portfolio_values[-1]\n",
    "    returns = df['Portfolio Value'].pct_change().dropna()\n",
    "    sharpe_ratio = (252**0.5) * returns.mean() / returns.std()  # Assuming 252 trading days in a year\n",
    "    total_trades = len(df[df['Order'].abs() == 1])\n",
    "    winning_trades = len(df[(df['Order'] == -1) & (df['Close'] > df['Close'].shift(1))])\n",
    "    win_ratio = winning_trades / total_trades if total_trades > 0 else 0\n",
    "\n",
    "    performance = {\n",
    "        \"Final Portfolio Value\": final_portfolio_value,\n",
    "        \"Sharpe Ratio\": sharpe_ratio,\n",
    "        \"Number of Trades Executed\": total_trades,\n",
    "        \"Win Ratio\": win_ratio\n",
    "    }\n",
    "\n",
    "    return performance\n",
    "\n",
    "# Load your dataframe\n",
    "# Ensure that the 'Date' column is in datetime format and sort by date\n",
    "fin_df['Date'] = pd.to_datetime(fin_df['Date'])\n",
    "fin_df = fin_df.sort_values(by='Date')\n",
    "\n",
    "# Generate signals and calculate performance\n",
    "fin_df = generate_signals(fin_df)\n",
    "performance = calculate_performance(fin_df)\n",
    "\n",
    "# Print performance metrics\n",
    "print(f\"Final Portfolio Value: ${performance['Final Portfolio Value']:.2f}\")\n",
    "print(f\"Sharpe Ratio: {performance['Sharpe Ratio']:.2f}\")\n",
    "print(f\"Number of Trades Executed: {performance['Number of Trades Executed']}\")\n",
    "print(f\"Win Ratio: {performance['Win Ratio']:.2f}\")\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(fin_df['Date'], fin_df['Close'], label='Closing Price')\n",
    "\n",
    "# Plot buy signals\n",
    "buy_signals = fin_df[fin_df['Order'] == 1]\n",
    "plt.plot(buy_signals['Date'], buy_signals['Close'], '^', markersize=10, color='g', label='Buy Signal')\n",
    "\n",
    "# Plot sell signals\n",
    "sell_signals = fin_df[fin_df['Order'] == -1]\n",
    "plt.plot(sell_signals['Date'], sell_signals['Close'], 'v', markersize=10, color='r', label='Sell Signal')\n",
    "\n",
    "plt.title('Closing Price and Buy/Sell Signals')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Price')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Plot portfolio value\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(fin_df['Date'], fin_df['Portfolio Value'], label='Portfolio Value')\n",
    "plt.title('Portfolio Value Over Time')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Portfolio Value')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "final_path=current_directory+\"/signals.csv\"\n",
    "fin_df.to_csv('final_path', index=False)  # Adjust the path to your desired output file location\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7e0a550",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot buy signals\n",
    "buy_signals = fin_df[fin_df['Order'] == 1]\n",
    "plt.scatter(buy_signals['Date'], buy_signals['Close'], marker='^', color='green', label='Buy Signal', alpha=1)\n",
    "\n",
    "# Plot sell signals\n",
    "sell_signals = fin_df[fin_df['Order'] == -1]\n",
    "plt.scatter(sell_signals['Date'], sell_signals['Close'], marker='v', color='red', label='Sell Signal', alpha=1)\n",
    "\n",
    "plt.title('Closing Price and Buy/Sell Signals')\n",
    "plt.xlabel('Date')\n",
    "\n",
    "\n",
    "plt.ylabel('Price')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e58bb74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the Portfolio Value over Time\n",
    "plt.figure(figsize=(14, 7))\n",
    "plt.plot(fin_df['Date'], fin_df['Portfolio Value'], label='Portfolio Value', color='purple')\n",
    "plt.title('Portfolio Value Over Time')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Portfolio Value')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "# Print performance metrics\n",
    "print(f\"Final Portfolio Value: ${performance['Final Portfolio Value']:.2f}\")\n",
    "print(f\"Sharpe Ratio: {performance['Sharpe Ratio']:.2f}\")\n",
    "print(f\"Number of Trades Executed: {performance['Number of Trades Executed']}\")\n",
    "print(f\"Win Ratio: {performance['Win Ratio']:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89bd13aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e17ee553",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb3e3b0e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7363db6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f52c782",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dacc77ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27cbcf5b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa299664",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a26c3428",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab43a31d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e6848d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b38301d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "449a93fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48d0a7b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7626bbd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55507294",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23c706ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5243bf7a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e005fde",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cad8cc0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "893bb2a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e06cc483",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e2d7f4c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b977bcea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f797d87c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b236ea92",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c8510cf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
